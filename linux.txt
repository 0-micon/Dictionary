Documentation
	1. The man pages (short for manual pages)
		Linux man pages online: http://man7.org/linux/man-pages/
	2. GNU Info
		info
		info <topic name>
	3. The help command and --help option
	Other documentation sources.
		Gentoo Handbook: https://www.gentoo.org/support/documentation/
		Ubuntu Documentation: https://help.ubuntu.com/community/CommunityHelpWiki
man
	man –f generates the same result as typing whatis
	man –k generates the same result as typing apropos
	The default order is specified in /etc/man_db.conf and is roughly (but not exactly) in ascending numerical order by section.
	man -a displays all pages with the given name in all chapters, one after the other.
info
	n: next node
	p: previous node
	u: up in the index
Graphical Help System
	GNOME: gnome-help or yelp; CTRL-l to show the location bar.
		yelp man:cat
	KDE: khelpcenter
Linux Distribution List.
	https://lwn.net/Distributions/
RHEL
	Red Hat Enterprise Linux: CentOS, Scientific Linux, Oracle Linux.
	It uses the RPM-based yum package manager to install, update, and remove packages in the system.
SUSE
	SUSE, SUSE Linux Enterprise Server (SLES), and openSUSE.
	SUSE Linux Enterprise Server (SLES) is upstream for openSUSE.
	It uses the RPM-based zypper package manager to install, update, and remove packages in the system.
	It includes the YaST (Yet Another Setup Tool) application for system administration purposes.
Debian
	Debian, Ubuntu, Linux Mint.
	It uses the DPKG-based APT package manager (using apt-get, apt-cache, etc.) to install, update, and remove packages in the system.
filesystem
	A method for storing and organizing files in Linux.
		Examples: ext3, ext4, FAT, XFS, Btrfs.
	Different types of filesystems supported by Linux:
	1. Conventional disk filesystems
		ext2, ext3, ext4, XFS, Btrfs, JFS, NTFS, etc.
	2. Flash storage filesystems
		ubifs, JFFS2, YAFFS, etc.
	3. Database filesystems
	4. Special purpose filesystems
		procfs, sysfs, tmpfs, squashfs, debugfs, etc.
FHS
	Filesystem Hierarchy
	All Linux filesystem names are case-sensitive.
	Multiple drives and/or partitions are mounted as directories in the single filesystem.
	Removable media such as USB drives and CDs and DVDs will show up as mounted at /run/media/{username}/{disklabel} for recent Linux systems, or under /media for older distributions.
	Many distributions distinguish between core utilities needed for proper system operation and other programs, and place the latter in directories under /usr (think user).
	Filesystem Hierarchy Standard:
		https://refspecs.linuxfoundation.org/FHS_3.0/fhs-3.0.pdf
	/bin/ - essential user command binaries required by all system users, such as cat, cp, ls, mv, ps, and rm
	/boot/ - static files of the boot loader; essential files needed to boot the system. For every alternative kernel installed on the system there are four files: vmlinuz, initramfs, config, System.map. Each of these files has a kernel version appended to its name. The Grand Unified Bootloader (GRUB) files such as /boot/grub/grub.conf or /boot/grub2/grub2.cfg are also found under the /boot directory.
		vmlinuz - The compressed Linux kernel, required for booting;
		initramfs - The initial ram filesystem, required for booting, sometimes called initrd, not initramfs;
		config - The kernel configuration file, only used for debugging and bookkeeping;
		System.map - Kernel symbol table, only used for debugging;
	/dev/ - device files; it contains device nodes, a type of pseudo-file used by most hardware and software devices, except for network devices.
	/dev/random/ - pool of random numbers
	/dev/urandom/ - pool of pseudo-random bits
	/etc/ - host-specific system configuration (required directories: opt, x11, sgml, xml); It is for system configuration files. It contains no binary programs, although there are some executable scripts.
		/etc/resolv.conf - tells the system where to go on the network to obtain host name to IP address mappings (DNS).
		/etc/passwd, /etc/shadow, /etc/group - files for managing user accounts
		Note: /etc is for system-wide configuration files and only the superuser can modify files there. User-specific configuration files are always found under their home directory.
	/home/ - user home directories
	/lib/ - essential shared libraries and kernel modules
		Note: Most of these are what is known as dynamically loaded libraries (also known as shared libraries or Shared Objects (SO)). On some Linux distributions there exists a /lib64 directory containing 64-bit libraries, while /lib contains 32-bit versions.
		/lib/modules/<kernel-version-number> - Kernel modules (kernel code, often device drivers, that can be loaded and unloaded without re-starting the system).
	/media/ - mount point for removable media
	/mnt/ - mount point for a temporarily mounted filesystems
	/opt/ - add-on or optional application software packages
	/run/ - data relevant to running processes
	/sbin/ - system binaries, essential binaries related to system administration, such as fsck and shutdown
		Note: Commands that are not essential (theoretically) for the system to boot or operate in single-user mode are placed in the /usr/bin and /usr/sbin directories. Historically, this was done so /usr could be mounted as a separate filesystem that could be mounted at a later stage of system startup or even over a network. However, nowadays most find this distinction is obsolete. In fact, many distributions have been discovered to be unable to boot with this separation, as this modality had not been used or tested for a long time. Thus, on some of the newest Linux distributions /usr/bin and /bin are actually just symbolically linked together, as are /usr/sbin and /sbin.
	/srv/ - data for services provided by the system; seldom used
	/tmp/ - temporary files
	/usr/ - (multi-)user utilities and applications (required directories: bin, include, lib, local, sbin, share)
	/var/ - variable files; it contains files that are expected to change in size and content as the system is running (var stands for variable).
		/var/log - system log files
		/var/lib - packages and database files
		/var/spool - print queues
		/var/tmp - temporary files
		Note: The /var directory may be put on its own filesystem so that growth of the files can be accommodated and the file sizes do not fatally affect the system. Network services directories such as /var/ftp (the FTP service) and /var/www (the HTTP web service) are also found under /var.
	/root/ - home directory for the root user
	/proc/ - virtual filesystem documenting kernel and process status as text files; This filesystem contains files and directories that mimic kernel structures and configuration information. It does not contain real files, but runtime system information, e.g. system memory, devices mounted, hardware configuration, etc. /proc has subdirectories as well.
		/proc/cpuinfo
		/proc/interrupts
		/proc/meminfo
		/proc/mounts
		/proc/partitions
		/proc/version
	There are some additional directories to be found under the root directory:
	/sys/ - Virtual pseudo-filesystem giving information about the system and the hardware. Can be used to alter system parameters and for debugging purposes.
/bin
	There must be no subdirectories in /bin
	The following commands, or symbolic links to commands, are required in /bin:
	cat - To concatenate files to standard output
	chgrp - To change file group ownership
	chmod - To change file access permissions
	chown - To change file owner and group
	cp - To copy files and directories
	date - To print or set the system data and time
	dd - To convert and copy a file
	df - To report filesystem disk space usage
	dmesg - To print or control the kernel message buffer
	echo - To display a line of text
	false - To do nothing, unsuccessfully
	hostname - To show or set the system's host name
	kill - To send signals to processes
	ln - To make links between files
	login - To begin a session on the system
	ls - To list directory contents
	mkdir - To make directories
	mknod - To make block or character special files
	more - To page through text
	mount - To mount a filesystem
	mv - To move/rename files
	ps - To report process status
	pwd - To print name of current working directory
	rm - To remove files or directories
	rmdir - To remove empty directories
	sed - stream editor
	sh - POSIX compatible command shell
	stty - To change and print terminal line settings
	su - To change user ID
	sync - To flush filesystem buffers
	true - To do nothing, successfully
	umount - To unmount file systems
	uname - To print system information
	The following programs, or symbolic links to programs, can be in /bin
	csh - C shell
	ed - editor
	tar - archiving utility
	cpio - archiving utility
	gzip - The GNU compression utility
	gunzip - The GNU uncompression utility
	zcat - The GNU uncompression utility
	netstat - The network statistics utility
	ping - The ICMP network test utility
/usr
	contains theoretically non-essential programs and scripts (in the sense that they should not be needed to initially boot the system) and has at least the following sub-directories:
	/usr/include - Header files used to compile applications
	/usr/lib - Libraries for programs in /usr/bin and /usr/sbin
	/usr/lib64 - 64-bit libraries for 64-bit programs in /usr/bin and /usr/sbin
	/usr/sbin - Non-essential system binaries, such as system daemons
	/usr/share - Shared data used by applications, generally architecture-independent
	/usr/src - Source code, usually for the Linux kernel
	/usr/local - Data and programs specific to the local machine. Subdirectories include bin, sbin, lib, share, include, etc.
	/usr/bin - This is the primary directory of executable commands on the system
/dev/null
	Pseudofile. (It is also called the bit bucket or black hole.)
	All data written to it is discarded and write operations never return a failure condition.
		ls -lR /tmp > /dev/null # the entire standard output stream is ignored, but any errors will still appear on the console
		ls -lR /tmp >& /dev/null # both stdout and stderr will be dumped into /dev/null
filesystem top node
	the root or simply "/"
boot loader
	A program that boots the operating system: GRUB, ISOLINUX.
	The boot loader is usually stored on one of the hard disks in the system, either in the boot sector (for traditional BIOS/MBR systems) or the EFI partition (for more recent (Unified) Extensible Firmware Interface or EFI/UEFI systems). Up to this stage, the machine does not access any mass storage media. Thereafter, information on date, time, and the most important peripherals are loaded from the CMOS values (after a technology used for the battery-powered memory store which allows the system to keep track of the date and time even when it is powered off).
		GRUB - GRand Unified Boot loader
		ISOLINUX - booting from removable media
		DAS U-Boot - booting on embedded devices/appliances
	When booting Linux, the boot loader is responsible for loading the kernel image and the initial RAM disk or filesystem (which contains some critical files and device drivers needed to start the system) into memory.
	The second stage boot loader resides under /boot. A splash screen is displayed, which allows us to choose which operating system (OS) to boot. After choosing the OS, the boot loader loads the kernel of the selected operating system into RAM and passes control to it. The boot loader loads the selected kernel image and passes control to it. Kernels are almost always compressed, so its first job is to uncompress itself. After this, it will check and analyze the system hardware and initialize any hardware device drivers built into the kernel.
initramfs
	Initial RAM Disk:
	1. mount proper root filesystem
	2. providing kernel functionality
	3. locating devices
	4. locating drivers and load them
	5. checking for errors in root filesystem
	The initramfs filesystem image contains programs and binary files that perform all actions needed to mount the proper root filesystem, like providing kernel functionality for the needed filesystem and device drivers for mass storage controllers with a facility called udev (for user device), which is responsible for figuring out which devices are present, locating the device drivers they need to operate properly, and loading them. After the root filesystem has been found, it is checked for errors and mounted.
	The mount program instructs the operating system that a filesystem is ready for use, and associates it with a particular point in the overall hierarchy of the filesystem (the mount point).
	If this is successful, the initramfs is cleared from RAM and the init program on the root filesystem (/sbin/init) is executed.
	If special hardware drivers are needed before the mass storage can be accessed, they must be in the initramfs image.
/sbin/init
	init handles the mounting and pivoting over to the final real root filesystem.
	Once the kernel has set up all its hardware and mounted the root filesystem, the kernel runs /sbin/init. This then becomes the initial process, which then starts other processes to get the system running. Most other processes on the system trace their origin ultimately to init.
		Exceptions include the so-called kernel processes. These are started by the kernel directly, and their job is to manage internal operating system details.
	Near the end of the boot process, init starts a number of text-mode login prompts. These enable you to type your username, followed by your password, and to eventually get a command shell. However, if you are running a system with a graphical login interface, you will not see these at first.
	Besides starting the system, init is responsible for keeping the system running and for shutting it down cleanly. One of its responsibilities is to act when necessary as a manager for all non-kernel processes; it cleans up after them upon completion, and restarts user login services as needed when users log in and out, and does the same for other background system services.
systemd
	/sbin/init now just points to /lib/systemd/systemd; i.e. systemd takes over the init process.
	One systemd command - systemctl is used for most basic tasks.
systemctl
	sudo systemctl start|stop|restart nfs.service - to start, stop, restart a service (using nfs as an example) on a currently running system
	sudo systemctl enable|disable nfs.service - to enable or disable a system service from starting up at system boot
	sudo systemctl restart NetworkManager
	sudo systemctl restart network
	sudo service NetworkManager restart
	sudo service network restart
service
	A program that runs as a background process.
		Examples: httpd, nfsd, ntpd, ftpd, named.
X Window System
	The standard toolkit and protocol to build graphical user interfaces on nearly all Linux systems.
	The X server, which actually provides the GUI, uses the /etc/X11/xorg.conf file as its configuration file if it exists.
desktop environment
	A graphical user interface on top of the operating system.
		Examples: GNOME, KDE, Xfce, Fluxbox.
Shell
	The command line interpreter that interprets the command line input and instructs the operating system to perform any necessary tasks and commands.
		Examples: bash, tcsh, zsh.
MBR
	Master Boot Record also known as First Sector of the Hard Disk.
	For systems using the BIOS/MBR method the size of the MBR is just 512 bytes.
	For systems using the EFI/UEFI method, UEFI firmware reads its Boot Manager data to determine which UEFI application is to be launched and from where (i.e. from which disk and partition the EFI partition can be found). The firmware then launches the UEFI application, for example GRUB, as defined in the boot entry in the firmware's boot manager. This procedure is more complicated, but more versatile than the older MBR methods.
BIOS
		The Basic Input/Output System initializes the hardware, including the screen and keyboard, and tests the main memory.
		This process is also called POST (Power On Self Test).
boot process
	Power ON
	BIOS
		The BIOS software is stored on a ROM chip on the motherboard. After this, the remainder of the boot process is controlled by the operating system (OS).
	MBR
	Boot Loader
	Kernel (Linux OS)
	Initial RAM disk
		initramfs image
	/sbin/init
		parent process
	Command Shell
		using getty
		Text-Mode Logins
		Most distributions start six text terminals and one graphics terminal starting with F1 or F2.
	X Windows System
		Graphical User Interface
X Windows System
	Session manager
		starts and maintains the components of the graphical session
	Window manager
		controls the placement and movement of windows, window title-bars, and controls
	A set of utilities
	You can start it manually from the command line (startx). Or you can start the display manager (gdm, lightdm, kdm, xdm, etc.).
gnome-tweak-tool
	tool to adjust advanced configuration settings for GNOME.
Check for Update, and Upgrade
	sudo apt-get update
	sudo apt upgrade -y
Clean up
	sudo apt-get autoclean
	sudo apt-get clean
	sudo apt-get autoremove
Install Multimedia Plug-in
	sudo apt-get install mint-meta-codecs
shortcuts
	Alt+F2 - Run dialog
	Ctrl+Alt+Down - Show the window selection screen
	Ctrl+Alt+Up, Alt+F1 - Show the workspace selection screen
	Super+D - Show desktop
	Alt+Space - Activate window menu
	Alt+F10 - Toggle maximization state
	Ctrl+Alt+T - Launch terminal
	Ctrl+Alt+F1...F6 - Switch to a Virtual Terminal
xdpyinfo | grep dim
	current screen resolution
Network Manager
	Network Manager was developed to make things easier and more uniform across distributions.
	It can list all available networks (wired or wireless), allow the choice of a wired, wireless, or mobile broadband network, handle passwords, and set up Virtual Private Networks (VPNs).
	For static configurations that do not use DHCP, manual setup can also be done easily through Network Manager.
	You can also change the Ethernet Media Access Control (MAC) address if your hardware supports it.
Package Management
	Both package management systems operate on two distinct levels: a low-level tool (such as dpkg or rpm) takes care of the details of unpacking individual packages, running scripts, getting the software installed correctly, while a high-level tool (such as apt-get, yum, dnf or zypper) works with groups of packages, downloads packages from the vendor, and figures out dependencies.
		Debian -> dpkg -> apt-get
		SUSE -> rpm -> zypper
		Red Hat -> rpm -> yum
dpkg
	Debian package manager. It can install, remove, and build packages.
	Unlike higher-level package management systems, it does not automatically download and install packages and satisfy their dependencies.
	For Debian-based systems, the higher-level package management system is the apt (Advanced Package Tool) system of utilities.
apt
	Advanced Package Tool For Debian-based systems
	Generally, while each distribution within the Debian family uses apt, it creates its own user interface on top of it.
		apt-get, apt-cache, aptitude, synaptic, Ubuntu Software Center, Update Manager, etc.
	Most apt repositories target a particular distribution (like Ubuntu), and often software distributors ship with multiple repositories to support multiple distributions.
rpm
	Red Hat Package Manager
	It was developed by Red Hat, and adopted by a number of other distributions, including openSUSE, Mandriva, CentOS, Oracle Linux, and others.
	The high-level package manager differs between distributions:
	yum (Yellowdog Updater, Modified) - Red Hat family distributions have historically used its repository format, although recent Fedora uses a replacement, dnf, still using the same format.
	SUSE family distributions also use RPM, but use the zypper interface.
	The GNOME project also uses PackageKit as a unified interface.
YaST
	(Yet another Setup Tool) software manager
	It is an RPM-based application.
	You can add, remove, or update packages using this application.
yum
	Yellowdog Updater Modified is an open source command-line package-management utility for the RPM-compatible Linux systems that belongs to the Red Hat/Fedora family. It has both command line and graphical user interfaces.
	Recent Fedora versions have replaced yum with a new utility called dnf, which has less historical baggage, has nice new capabilities and is mostly backwards-compatible with yum for day-to-day commands.
zypper
	The package management system for the SUSE/openSUSE family and is also based on RPM.
	It also allows you to manage repositories from the command line.
	It is fairly straightforward to use and resembles yum quite closely.
basic packaging commands
	Install package
		rpm -i foo.rpm
		dpkg --install foo.deb
	Install package, dependencies
		yum install foo
		apt-get install foo
	Remove package
		rpm -e foo.rpm
		dpkg --remove foo.deb
	Remove package, dependencies
		yum remove foo
		apt-get autoremove foo
	Update package
		rpm -U foo.rpm
		dpkg --install foo.deb
	Update package, dependencies
		yum update foo
		apt-get install foo
	Update entire system
		yum update
		apt-get dist-upgrade
	Show all installed packages
		rpm -qa
		yum list installed
		dpkg --list
	Get information on package
		rpm -qil foo
		dpkg --listfiles foo
	Show packages named foo
		yum list "foo"
		apt-cache search foo
	Show all available packages
		yum list
		apt-cache dumpavail foo
	What package is file part of?
		rpm -qf file
		dpkg --search file
software
	FileZilla - Intuitive graphical FTP client that supports FTP, Secure FTP (SFTP), and FTP Secured (FTPS). Used to transfer files to/from (FTP) servers.
	Pidgin - To access GTalk, AIM, ICQ, MSN, IRC and other messaging networks.
	Ekiga - To connect to Voice over Internet Protocol (VoIP) networks.
	Hexchat- To access Internet Relay Chat (IRC) networks.
Basic Utilities
	w: shows who is logged on and what they are doing
	cat: to type out a file (or combine files)
	head: to show the first few lines of a file
	tail: to show the last few lines of a file
	man: to view documentation
	sudo: to run programs using the security privileges of another user, generally root (superuser)
	shutdown: to reboot or shutdown the system
		sudo shutdown -h 10:00 "Shutting down for scheduled maintenance."
		sudo shutdown -r 10:00 "Rebooting is scheduled."
	which: to view the pathnames of the files (links)
		which java
	whereis: to locate the binaries, source and manual files
		whereis python/
	pwd: to display the present working directory
	tree: to list contents of directories in a tree-like format
		tree -d
	pushd/popd/dirs: to change the directory with a stack-like directory history
	touch: to set or update the access, change, and modify times of files. By default, it resets a file's timestamp to match the current time.
		to create an empty file: touch <filename>
		to set the date and timestamp of the file to a specific value: touch -t 12091600 <filename>
	mkdir/rmdir: to create/remove a directory
		Note: The directory must be empty or rmdir will fail. To remove a directory and all of its contents: rm -rf
	mv: rename/move a file/directory
	rm: remove a file
		rm –f: forcefully remove a file
		rm –i: interactively remove a file
	at: to schedule future processes
	df: to report file system disk space usage
		df -Th
	whoami: to identify the current user
	who: to list the currently logged-on users
		who -a
	id: to print real and effective user and group IDs
	wget: network downloader
	curl: to transfer data from or to a server
		curl -o saved.html http://www.mysite.com
	last: shows the last time each user logged into the system
sudo
	executes a command as another user. When the command is complete, you will return to being a normal unprivileged user.
	sudo configuration files are stored in the /etc/sudoers file and in the /etc/sudoers.d/ directory. By default, the sudoers.d directory is empty.
		sudo visudo
	sudo has the ability to keep track of unsuccessful attempts at gaining root access.
	By default, sudo commands and any failures are logged in /var/log/auth.log under the Debian distribution family, and in /var/log/messages and/or /var/log/secure on other systems.
	Whenever sudo is invoked, a trigger will look at /etc/sudoers and the files in /etc/sudoers.d to determine if the user has the right to use sudo and what the scope of their privilege is. The basic structure of an entry is: who where = (as_whom) what
	Steps for Setting Up and Running:
	1. $ su {password}
	2. Create a configuration file to enable your user account to use sudo. Typically, this file is created in the /etc/sudoers.d/ directory with the name of the file the same as your username.
		# echo "student ALL=(ALL) ALL" > /etc/sudoers.d/student
	3. Some Linux distributions will complain if we do not also change permissions on the file.
		# chmod 440 /etc/sudoers.d/student
Turning Off/On the Graphical Desktop
	$ sudo systemctl stop gdm (or sudo telinit 3)
	$ sudo systemctl start gdm (or sudo telinit 5)
		On Ubuntu versions before 18.04 LTS, substitute lightdm for gdm.
links
	ln: to create hard links and (with the -s option) soft links, also known as symbolic links or symlinks.
	1. Hard Links
	A hard link, called link1, is created with the command: ln file1 link1
	2. Soft (Symbolic) Links
	Soft (or Symbolic) links are created with the -s option: ln -s file1 link2
	Unlike hard links, soft links can point to objects even on different filesystems, partitions, and/or disks and other media, which may or may not be currently available or even exist.
	In the case where the link does not point to a currently available or existing object, you obtain a dangling link.
file viewing
	cat: for viewing files that are not very long; it does not provide any scroll-back.
	tac: to look at a file backwards, starting with the last line.
	less: to view larger files because it is a paging program. It pauses at each screen full of text, provides scroll-back capabilities, and lets you search and navigate within the file.
		Note: Use / to search for a pattern in the forward direction and ? for a pattern in the backward direction. An older program named more is still used, but has fewer capabilities: "less is more".
	tail: to print the last 10 lines of a file by default. You can change the number of lines by doing -n 15 or just -15 if you wanted to look at the last 15 lines instead of the default.
	head: The opposite of tail; by default, it prints the first 10 lines of a file.
file searching
	You can search for a filename containing specific characters using wildcards.
	? - any single character
	* - any string of characters
	[set] - any character in the set of characters
		[adf] will match any occurrence of 'a', 'd', or 'f'
	[!set] - any character not in the set of characters
	
	locate: To perform a search taking advantage of a previously constructed database of files and directories on the system, matching all entries that contain a specified character string. locate utilizes a database created by a related utility, updatedb.
		locate zip | grep bin
	find: To recurse down the filesystem tree from any particular directory (or set of directories) and locates files that match specified conditions. Commonly used options to shorten the list include -name (only list files with a certain pattern in their name), -iname (also ignore the case of file names), and -type (which will restrict the results to files of a certain specified type, such as d for directory, l for symbolic link, or f for a regular file, etc.). Another good use of find is being able to run commands on the files that match your search criteria. The -exec option is used for this purpose.
	Note: One can also use the -ok option, which behaves the same as -exec, except that find will prompt you for permission before executing the command. This makes it a good way to test your results before blindly executing any potentially dangerous commands.
		Searching for files and directories named gcc: find /usr -name gcc
		Searching only for directories named gcc: find /usr -type d -name gcc
		Searching only for regular files named gcc: find /usr -type f -name gcc
		To find and remove all files that end with .swp: find -name "*.swp" -exec rm {} ’;’
		Note: The {} (squiggly brackets) is a placeholder that will be filled with all the file names that result from the find expression, and the preceding command will be run on each one individually. Also you have to end the command with either ’;’ (including the single-quotes) or "\;". Both forms are fine.
		To find files based on time: find / -ctime 3
		Note: -ctime is when the inode metadata (i.e. file ownership, permissions, etc.) last changed; it is often, but not necessarily, when the file was first created. -atime to search for accessed/last read or -mtime for modified/last written times. The number is the number of days and can be expressed as either a number (n) that means exactly that value, +n, which means greater than that number, or -n, which means less than that number. There are similar options for times in minutes (as in -cmin, -amin, and -mmin).
		To find files based on sizes: find / -size 0
		Note: the size here is in 512-byte blocks, by default; you can also specify bytes (c), kilobytes (k), megabytes (M), gigabytes (G), etc. As with the time numbers above, file sizes can also be exact numbers (n), +n or -n.
		To find files greater than 10 MB in size and running a command on those files: find / -size +10M -exec command {} ’;’
Standard File Streams
	0 stdin - standard input
		do_something < input-file
	1 stdout - standard output
		do_something > output-file
	2 stderr - standard error
		do_something 2> error-file
	A special shorthand notation can send anything written to file descriptor 2 (stderr) to the same place as file descriptor 1 (stdout): 2>&1.
		do_something > all-output-file 2>&1
	Note: bash permits an easier syntax: >&
		do_something >& all-output-file
pipe
	You can pipe the output of one command or program into another as its input.
	In order to do this, use the vertical-bar | (pipe symbol) between commands.
		command1 | command2 | command3
Process and Thread IDs
	PID - Unique Process ID number
	PPID - Parent Process ID. If the parent dies, the PPID will refer to an adoptive parent; on recent kernels, this is kthreadd which has PPID=2.
	TID - Thread ID. This is the same as the PID for single-threaded processes. For a multi-threaded process, each thread shares the same PID, but has a unique TID.
	RUID - Real User ID.
	EUID - Effective UID. The EUID may or may not be the same as the RUID.
	RGID - Real Group ID.
	EGID - Effective Group ID. The access rights of the group are determined by the EGID.
Terminating a Process
	kill -SIGKILL <pid>
	kill -9 <pid>
	Note: you can only kill your own processes; those belonging to another user are off limits, unless you are root.
Background Process
	By default, all jobs are executed in the foreground. You can put a job in the background by suffixing & to the command.
		updatedb &
	You can either use CTRL-Z to suspend a foreground job or CTRL-C to terminate a foreground job and can always use the bg and fg commands to run a process in the background and foreground, respectively.
	jobs: displays all jobs running in background.
	jobs -l: provides the same information as jobs, including the PID of the background jobs.
ps
	ps provides information about currently running processes keyed by PID.
	Without options, ps will display all processes running under the current shell.
	-u: to display information of processes for a specified username
	-ef: to display all the processes in the system in full detail
	-eLf: to display one line of information for every thread (a process can contain multiple threads)
	aux: to display all processes of all users
	axo: to specify which attributes you want to view
		ps axo stat,priority,pid,pcpu,comm
pstree
	displays the processes running on the system in the form of a tree diagram showing the relationship between a process and its parent process and any other processes that it created.
	Repeated entries of a process are not displayed, and threads are displayed in curly braces.
top
	Interactive Keys:
	t: Display/hide summary information (rows 2 and 3)
	m: Display/hide memory information (rows 4 and 5)
	A: Sort the process list by top resource consumers
	r: Re-nice (change the priority of) a specific processes
	k: Kill a specific process
	f: Enter the top configuration screen
	o: Interactively select a new sort order in the process list
cron
	is a time-based scheduling utility program. It can launch routine background jobs at specific times and/or days on an on-going basis.
	It is driven by a configuration file: /etc/crontab (cron table), which contains the various shell commands that need to be run at the properly scheduled times. There are both system-wide crontab files and individual user-based ones. Each line of a crontab file represents a job, and is composed of a so-called CRON expression, followed by a shell command to execute.
	crontab -e: opens the crontab editor to edit existing jobs or to create new jobs.
	Each line of the crontab file will contain 6 fields:
	1. MIN: Minutes (0 to 59)
	2. HOUR: Hour field (0 to 23)
	3. DOM: Day of Month (1-31)
	4. MON: Month field (1-12)
	5. DOW: Day Of Week (0-6) (0 = Sunday)
	6. CMD: Command. Any command to be executed.
		* * * * * /usr/local/bin/execute/this/script.sh: will schedule a job to execute 'script.sh' every minute of every hour of every day of the month, and every month and every day in the week.
		30 08 10 06 * /home/sysadmin/full-backup: will schedule a full-backup at 8.30 a.m., 10-June, irrespective of the day of the week.
		0 10 * * * /tmp/myjob.sh: every day at 10 AM. If the machine is not up at 10 AM on a given day, anacron will run the job at a suitable time.
		crontab -r: to remove a task.
mounting/unmounting
	The mount command is used to attach a filesystem (local to the computer or on a network) somewhere within the filesystem tree. The basic arguments are the device node and mount point.
		sudo mount /dev/sda5 /home
	There are other ways to specify the partition other than the device node, such as using the disk label or UUID.
	Typing mount without any arguments will show all presently mounted filesystems.
	The command df -Th (disk-free) will display information about mounted filesystems, including the filesystem type, and usage statistics about currently used and available space.
	To unmount the partition, the command would be umount.
		sudo umount /home
	Edit /etc/fstab for automatic mounting at the system start up.
		man fstab
nfs
	1. On the server
		sudo systemctl start nfs
	The text file /etc/exports contains the directories and permissions that a host is willing to share with other systems over NFS.
		/projects *.example.com(rw)
	After modifying the /etc/exports file, you can use the exportfs -av command to notify Linux about the directories you are allowing to be remotely mounted using NFS.
	You can also restart NFS with sudo systemctl restart nfs, but this is heavier, as it halts NFS for a short while before starting it up again.
	To make sure the NFS service starts whenever the system is booted, issue sudo systemctl enable nfs.
	2. On the client
	On the client machine, if it is desired to have the remote filesystem mounted automatically upon system boot, the /etc/fstab file is modified to accomplish this. Use the nofail option in fstab in case the NFS server is not live at boot.
		servername:/projects /mnt/nfs/projects nfs defaults 0 0
	You can also mount the remote filesystem without a reboot or as a one-time mount by directly using the mount command.
		sudo mount servername:/projects /mnt/nfs/projects
removable media
	/media, /run and /mnt directories
diff
	to compare files and directories.
		diff [options] <filename1> <filename2>
	The patch files are produced by running diff with the correct options.
		diff -Nur originalfile newfile > patchfile
	Useful options:
	-c: Provides a listing of differences that include three lines of context before and after the lines differing in content
	-r: Used to recursively compare subdirectories, as well as the current directory
	-i: Ignore the case of letters
	-w: Ignore differences in spaces and tabs (white space)
	-q: Be quiet: only report if files are different without listing the differences
	Note: diff is meant to be used for text files; for binary files, one can use cmp.
diff3
	to compare three files at once. It uses one file as the reference basis for the other two.
		diff3 MY-FILE COMMON-FILE YOUR-FILE
patch
	patch -p1 < patchfile
	patch originalfile patchfile
	Note: The first usage is more common, as it is often used to apply changes to an entire directory tree, rather than just one file, as in the second example.
file
	determines file type
	It tests each argument in an attempt to classify it. There are three sets of tests, performed in this order: filesystem tests, magic tests, and language tests. The first test that succeeds causes the file type to be printed.
rsync
	file-copying tool
	rsync source-file destination-file
		rsync -r project-X archive-machine:archives/project-X - to back up a project directory
		rsync --progress -avrxH  --delete sourcedir destdir
compressing data
	gzip: The most frequently used Linux compression utility
		gzip * - Compresses all files in the current directory; each file is compressed and renamed with a .gz extension
		gzip -r projectX - Compresses all files in the projectX directory, along with all files in all of the directories under projectX
		gunzip foo - De-compresses foo found in the file foo.gz. Under the hood, the gunzip command is actually the same as gzip –d
	bzip2: Produces files significantly smaller than those produced by gzip
		bzip2 * - Compresses all of the files in the current directory and replaces each file with a file renamed with a .bz2 extension
		bunzip2 *.bz2 - Decompresses all of the files with an extension of .bz2 in the current directory. Under the hood, bunzip2 is the same as calling bzip2 -d
	xz: The most space-efficient compression utility used in Linux
		xz * - Compresses all of the files in the current directory and replaces each file with one with a .xz extension
		xz foo - Compresses the file foo into foo.xz using the default compression level (-6), and removes foo if compression succeeds
		xz -dk bar.xz - Decompresses bar.xz into bar and does not remove bar.xz even if decompression is successful
		xz -dcf a.txt b.txt.xz > abcd.txt - Decompresses a mix of compressed and uncompressed files to standard output, using a single command
		xz -d *.xz - Decompresses the files compressed using xz
	zip: Is often required to examine and decompress archives from other operating systems
		zip backup * - Compresses all files in the current directory and places them in the file backup.zip
		zip -r backup.zip ~ - Archives your login directory (~) and all files and directories under it in the file backup.zip
		unzip backup.zip - Extracts all files in the file backup.zip and places them in the current directory
	Note: In addition, the tar utility is often used to group files in an archive and then compress the whole archive at once.
tar
	Historically, tar stood for "tape archive" and was used to archive files to a magnetic tape. It allows you to create or extract files from an archive file, often called a tarball. At the same time, you can optionally compress while creating the archive, and decompress while extracting its contents.
		tar xvf mydir.tar - Extract all the files in mydir.tar into the mydir directory
		tar zcvf mydir.tar.gz mydir - Create the archive and compress with gzip
		tar jcvf mydir.tar.bz2 mydir - Create the archive and compress with bz2
		tar Jcvf mydir.tar.xz mydir - Create the archive and compress with xz
		tar xvf mydir.tar.gz - Extract all the files in mydir.tar.gz into the mydir directory. Note: You do not have to tell tar it is in gzip format
	You can separate out the archiving and compression stages, but this is slower and wastes space by creating an unneeded intermediary .tar file.
		tar cvf mydir.tar mydir ; gzip mydir.tar
		gunzip mydir.tar.gz ; tar xvf mydir.tar
dd
	Disk-to-Disk Copying.
creating files without using an editor
	1. Use echo repeatedly
		echo line one > myfile
		echo line two >> myfile
		echo line three >> myfile
	2. Use cat combined with redirection
		cat << EOF > myfile
		> line one
		> line two
		> line three
		> EOF
nano
	nano <filename>
	If the file does not exist, it will be created.
	Some commands:
	CTRL-G: Display the help screen.
	CTRL-O: Write to a file.
	CTRL-X: Exit a file.
	CTRL-R: Insert contents from another file to the current buffer.
	CTRL-C: Cancels previous commands.
vi
	Modes:
	1. Command
	By default, vi starts in Command mode. Each key is an editor command. Keyboard strokes are interpreted as commands that can modify file contents.
	2. Insert
	Type i to switch to Insert mode from Command mode. Insert mode is used to enter (insert) text into a file. Insert mode is indicated by an “? INSERT ?” indicator at the bottom of the screen. Press Esc to exit Insert mode and return to Command mode.
	3. Line
	Type : to switch to the Line mode from Command mode. Each key is an external command, including operations such as writing the file contents to disk or exiting. Uses line editing commands inherited from older line editors. Most of these commands are actually no longer used. Some line editing commands are very powerful. Press Esc to exit Line mode and return to Command mode.
	Important commands:
	vi myfile - Start the vi editor and edit the myfile file
	vi -r myfile - Start vi and edit myfile in recovery mode from a system crash
	:r file2 - Read in file2 and insert at current position
	:w - Write to the file
	:w myfile - Write out the file to myfile
	:w! file2 - Overwrite file2
	:x or :wq - Exit vi and write out modified file
	:q - Quit vi
	:q! - Quit vi even though modifications have not been saved
	Changing Cursor Positions:
	arrow keys - To move up, down, left and right
	j or <ret> - To move one line down
	k - To move one line up
	h or Backspace - To move one character left
	l or Space - To move one character right
	0 - To move to beginning of line
	$ - To move to end of line
	w - To move to beginning of next word
	:0 or 1G - To move to beginning of file
	:n or nG - To move to line n
	:$ or G - To move to last line in file
	CTRL-F or Page Down - To move forward one page
	CTRL-B or Page Up - To move backward one page
	^l - To refresh and center screen
	Searching for Text:
	/pattern - Search forward for pattern
	?pattern - Search backward for pattern
	n - Move to next occurrence of search pattern
	N - Move to previous occurrence of search pattern
	Stop upon Escape key commands:
	a - Append text after cursor; 
	A - Append text at end of current line;
	i - Insert text before cursor;
	I - Insert text at beginning of current line;
	o - Start a new line below current line, insert text there;
	O - Start a new line above current line, insert text there;
	R - Replace text starting with current position;
	Other commands:
	r - Replace character at current position
	x - Delete character at current position
	Nx - Delete N characters, starting at current position
	dw - Delete the word at the current position
	D - Delete the rest of the current line
	dd - Delete the current line
	Ndd or dNd - Delete N lines
	u - Undo the previous operation
	yy - Yank (copy) the current line and put it in buffer
	Nyy or yNy - Yank (copy) N lines and put it in buffer
	p - Paste at the current position the yanked line or lines from the buffer
	:sh - opens an external command shell
	:! {command} % - executes a command from within vi; % - the file currently being edited
emacs
	emacs myfile - Start emacs and edit myfile
	CTRL-x i - Insert prompted for file at current position
	CTRL-x s - Save all files
	CTRL-x CTRL-w - Write to the file giving a new name when prompted
	CTRL-x CTRL-s - Saves the current file 
	CTRL-x CTRL-c - Exit after being prompted to save any modified files
	CTRL-h  - for help and then the letter t for tutorial
	Changing Cursor Positions:
	arrow keys: Use the arrow keys for up, down, left and right
	CTRL-n: One line down
	CTRL-p: One line up
	CTRL-f: One character forward/right
	CTRL-b: One character back/left
	CTRL-a: Move to beginning of line
	CTRL-e: Move to end of line
	Meta-f: Move to beginning of next word
	Meta-b: Move back to beginning of preceding word
	Meta-<: Move to beginning of file
	Meta-g-g-n: Move to line n (can also use 'Esc-x Goto-line n')
	Meta->: Move to end of file
	CTRL-v or Page Down: Move forward one page
	Meta-v or Page Up: Move backward one page
	CTRL-l: Refresh and center screen
	Searching for Text:
	CTRL-s: Search forward for prompted pattern, or for next pattern
	CTRL-r: Search backwards for prompted pattern, or for next pattern
	Working with Text:
	CTRL-o: Insert a blank line
	CTRL-d: Delete character at current position
	CTRL-k: Delete the rest of the current line
	CTRL-_: Undo the previous operation
	CTRL- (space or CTRL-@): Mark the beginning of the selected region. The end will be at the cursor position
	CTRL-w: Delete the current marked text and write it to the buffer
	CTRL-y: Insert at current cursor location whatever was most recently deleted
user startup files
	When you first login to Linux, /etc/profile is read and evaluated, after which the following files are searched (if they exist) in the listed order:
	1. ~/.bash_profile
	2. ~/.bash_login
	3. ~/.profile
	The Linux login shell evaluates whatever startup file that it comes across first and ignores the rest.
	However, every time you create a new shell, or terminal window, etc., you do not perform a full system login; only a file named ~/.bashrc file is read and evaluated.
alias
	defines or displays aliases.
	unalias removes an alias.
	Note: there should not be any spaces on either side of the equal sign and the alias definition needs to be placed within either single or double quotes if it contains any spaces.
groups
	All Linux users are assigned a unique user ID (uid), which is just an integer; normal users start with a uid of 1000 or greater.
	Linux uses groups for organizing users.
	Groups are collections of accounts with certain shared permissions. Permissions on various files and directories can be modified at the group level.
	Control of group membership is administered through the /etc/group file, which shows a list of groups and their members. By default, every user belongs to a default or primary group.
	When a user logs in, the group membership is set for their primary group and all the members enjoy the same level of access and privilege.
	Users also have one or more group IDs (gid), including a default one which is the same as the user ID.
	These numbers are associated with names through the files /etc/passwd and /etc/group.
	Groups are used to establish a set of users who have common interests for the purposes of access rights, privileges, and security considerations.
	Access rights to files (and devices) are granted on the basis of the user and the group they belong to.
adding/removing users/groups
	users: to print the user names currently logged in
	groups: to print the groups a user is in
	Note: Only the root user can add and remove users and groups.
	useradd: to add a new user
		sudo useradd -m student
		sudo passwd student
	userdel: to delete an existing user
		sudo userdel -r student
	groupadd: to add a new group
		sudo /usr/sbin/groupadd anewgroup
	usermod: to modify a user account
		sudo /usr/sbin/usermod -a -G anewgroup student
	groupmod: to change group properties, such as the Group ID (gid) with the -g option or its name with then -n option.
	groupdel: to delete an existing group
		sudo /usr/sbin/groupdel anewgroup
environment variables
	There are a number of ways to view the values of currently set environment variables: set, env, export, printenv.
		set | grep HIST
	By default, variables created within a script are only available to the current shell; child processes (sub-shells) will not have access to values that have been set or modified. Allowing child processes to see the values requires use of the export command. While child processes are allowed to modify the value of exported variables, the parent will not see any changes; exported variables are not shared, they are only copied and inherited.
		echo $SHELL - Show the value of a specific variable
		export VARIABLE=value (or VARIABLE=value; export VARIABLE) - Export a new variable value
		SDIRS=s_0* KROOT=/lib/modules/$(uname -r)/build make modules_install - Set environment variables to be fed as a one shot to a command
		$? - Exit status code
	To add a variable permanently edit ~/.bashrc and add: export VARIABLE=value.
PATH
	is an ordered list of directories (the path) which is scanned when a command is given to find the appropriate program or script to run. Each directory in the path is separated by colons (:).
	A null (empty) directory name (or ./) indicates the current directory at any given time.
		export PATH=$HOME/bin:$PATH
SHELL
	points to the user's default command shell (the program that is handling whatever you type in a command window, usually bash) and contains the full pathname to the shell.
RANDOM
	Environment variable to generate random numbers and other random data.
		for n in 1 2 3 ; do echo $RANDOM ; done
PS1
	is the primary prompt variable which controls what your command line prompt looks like.
	Special characters can be included in PS1:
	\u - User name
	\h - Host name
	\w - Current working directory
	\! - History number of this command
	\d - Date
	They must be surrounded in single quotes when they are used.
		export PS1='\u@\h:\w$ '
		export PS1='$ ' - To revert the changes
		OLD_PS1=$PS1
		PS1=$OLD_PS1
history
	CTRL-R: Search previously used commands
	!! (Pronounced as bang-bang): Execute the previous command
	Up/Down arrow keys: Browse through the list of commands previously executed
	!: Start a history substitution
	!$: Refer to the last argument in a line
	!n: Refer to the n-th command line
	!string: Refer to the most recent command starting with string
bash keyboard shortcuts
	CTRL-L: Clears the screen
	CTRL-D: Exits the current shell
	CTRL-Z: Puts the current process into suspended background
	CTRL-C: Kills the current process
	CTRL-H: Works the same as backspace
	CTRL-A: Goes to the beginning of the line
	CTRL-W: Deletes the word before the cursor
	CTRL-U: Deletes from beginning of line to cursor position
	CTRL-E: Goes to the end of the line
	Tab: Auto-completes files, directories, and binaries
file ownership
	Files have three kinds of permissions: read (r), write (w), execute (x). These are generally represented as in rwx. These permissions affect three groups of owners: user/owner (u), group (g), and others (o).
	As a result, you have the following three groups of three permissions:
	rwx:rwx:rwx
	u:g:o
	This kind of syntax can be difficult to type and remember, so one often uses a shorthand which lets you set all the permissions in one step. This is done with a simple algorithm, and a single digit suffices to specify all three permission bits for each entity. This digit is the sum of:
	4 if read permission is desired
	2 if write permission is desired
	1 if execute permission is desired.
	Thus, 7 means read/write/execute, 6 means read/write, and 5 means read/execute.
	Commands:
	chown: Used to change user ownership of a file or directory
	chgrp: Used to change group ownership
	chmod: Used to change the permissions on the file, which can be done separately for owner, group and the rest of the world (often named as other)
		chmod uo+x,g-w somefile
		chmod 755 somefile
cat
	is short for concatenate. It is often used to read and print files, as well as for simply viewing file contents.
		cat <filename>
	The main purpose of cat is to combine (concatenate) multiple files together.
		cat file1 file2 - Concatenate multiple files and display the output
		cat file1 file2 > newfile - Combine multiple files and save the output into a new file
		cat file >> existingfile - Append a file to the end of an existing file
		cat > file - Any subsequent lines typed will go into the file, until CTRL-D is typed
		cat >> file - Any subsequent lines are appended to the file, until CTRL-D is typed
		cat > <filename> << EOF - Note: EOF is case sensitive. One can also use another word, such as STOP.
tac
	(cat spelled backwards) prints the lines of a file in reverse order. Each line remains the same, but the order of lines is inverted. The syntax of tac is exactly the same as for cat.
		tac file
		tac file1 file2 > newfile
echo
	simply displays (echoes) text.
	The –e option, along with the following switches, is used to enable special character sequences, such as the newline character or horizontal tab.
	1) \n - represents newline
	2) \t - represents horizontal tab
		echo string > newfile: The specified string is placed in a new file
		echo string >> existingfile: The specified string is appended to the end of an already existing file
		echo $variable: The contents of the specified environment variable are displayed
sed
	a powerful text processing tool
	The -e command option allows you to specify multiple editing commands simultaneously at the command line. It is unnecessary if you only have one operation invoked.
	To convert 01/02/ to JAN/FEB/
	sed -e 's/01/JAN/' -e 's/02/FEB/' -e 's/03/MAR/' -e 's/04/APR/' -e 's/05/MAY/' \
	-e 's/06/JUN/' -e 's/07/JUL/' -e 's/08/AUG/' -e 's/09/SEP/' -e 's/10/OCT/' \
	-e 's/11/NOV/' -e 's/12/DEC/'
		sed -e command <filename>: Specify editing commands at the command line, operate on file and put the output on standard out (e.g., the terminal)
		sed -f scriptfile <filename>: Specify a scriptfile containing sed commands, operate on file and put output on standard out
		sed s/pattern/replace_string/ file: Substitute first string occurrence in every line
		sed s/pattern/replace_string/g file: Substitute all string occurrences in every line
		sed 1,3s/pattern/replace_string/g file: Substitute all string occurrences in a range of lines
		sed -i s/pattern/replace_string/g file: Save changes for string substitution in the same file
awk
	is used to extract and then print specific contents of a file and is often used to construct reports.
		awk command file: Specify a command directly at the command line
		awk -f scriptfile file: Specify a file that contains the script to be executed
	-F option allows you to specify a particular field separator character.
		awk '{ print $0 }' /etc/passwd: Print entire file
		awk -F: '{ print $1 }' /etc/passwd: Print first field (column) of every line, separated by a space
		awk -F: '{ print $1 $7 }' /etc/passwd: Print first and seventh field of every line
file manipulation
	sort: to rearrange the lines of a text file either in ascending or descending order, according to a sort key. You can also sort by particular fields of a file. The default sort key is the order of the ASCII characters (i.e. essentially alphabetically). When used with the -u option, sort checks for unique values after sorting the records (lines). It is equivalent to running uniq on the output of sort.
		sort <filename>: Sort the lines in the specified file, according to the characters at the beginning of each line
		cat file1 file2 | sort: Combine the two files, then sort the lines and display the output on the terminal
		sort -r <filename>: Sort the lines in reverse order
		sort -k 3 <filename>: Sort the lines by the 3rd field on each line instead of the beginning
		sort -u file1 file2 > file3: To remove duplicate entries from multiple files at once
	uniq: uniq removes duplicate consecutive lines in a text file and is useful for simplifying the text display.
		sort file1 file2 | uniq > file3: To remove duplicate entries from multiple files at once
		uniq -c filename: To count the number of duplicate entries
	paste: to combine fields (such as name or phone number) from different files, as well as combine lines from multiple files.
		-d: delimiters, which specify a list of delimiters to be used instead of tabs for separating consecutive values on a single line. Each delimiter is used in turn; when the list has been exhausted, paste begins again at the first delimiter.
		-s, which causes paste to append the data in series rather than in parallel; that is, in a horizontal rather than vertical fashion.
		paste file1 file2: To paste contents from two files
		paste -d, file1 file2: Common delimiters are 'space', 'tab', '|', 'comma', etc.
	join: to combine files on a common field
		join file1 file2
	split: to break up a file into equal-sized segments for easier viewing and manipulation. By default, split breaks up a file into 1000-line segments. By default, the x prefix is added.
		split infile <Prefix>
regular expressions
	Many text editors and utilities such as vi, sed, awk, find and grep work extensively with regular expressions.
	Search patterns and their usage:
	.(dot) - Match any single character
	a|z - Match a or z
	$ - Match end of string
	^ - Match beginning of string
	* - Match preceding item 0 or more times
grep
	is extensively used as a primary text searching tool. It scans files for specified patterns and can be used with regular expressions, as well as simple strings.
		grep [pattern] <filename>: Search for a pattern in a file and print all matching lines
		grep -v [pattern] <filename>: Print all lines that do not match the pattern
		grep [0-9] <filename>: Print the lines that contain the numbers 0 through 9
		grep -C 3 [pattern] <filename>: Print context of lines (specified number of lines above and below the pattern) for matching the pattern. Here, the number of lines is specified as 3
strings
	is used to extract all printable character strings found in the file or files given as arguments. It is useful in locating human-readable content embedded in binary files; for text files one can just use grep.
		strings book1.xls | grep my_string
tr
	to translate or delete characters
		tr [options] set1 [set2]
		tr abcdefghijklmnopqrstuvwxyz ABCDEFGHIJKLMNOPQRSTUVWXYZ - Convert lower case to upper case
		tr '{}' '()' < inputfile > outputfile - Translate braces into parenthesis
		echo "This is for testing" | tr [:space:] '\t' - Translate white-space to tabs
		echo "This   is   for    testing" | tr -s [:space:] - Squeeze repetition of characters using -s
		echo "the geek stuff" | tr -d 't' - Delete specified characters using -d option
		echo "my username is 432234" | tr -cd [:digit:] - Complement the sets using -c option
		tr -cd [:print:] < file.txt - Remove all non-printable character from a file
		tr -s '\n' ' ' < file.txt - Join all the lines in a file into a single line
tee
	takes the output from any command, and, while sending it to standard output, it also saves it to a file.
wc
	counts the number of lines, words, and characters in a file or list of files.
		wc /var/log/*.log
	Options:
	–l: Displays the number of lines
	-c: Displays the number of bytes
	-w: Displays the number of words
	By default, all three of these options are active.
cut
	is used for manipulating column-based files and is designed to extract specific columns. The default column separator is the tab character. A different delimiter can be given as a command option.
		ls -l | cut -d" " -f3
network configuration files
	/etc/network/ - for Debian family
	/etc/sysconfig/network - for Fedora and SUSE family
	nmtui - Text User Interface for controlling NetworkManager
	nmcli - command-line tool for controlling NetworkManager
network interface
	Network interfaces are a connection channel between a device and a network.
	Physically, network interfaces can proceed through a network interface card (NIC), or can be more abstractly implemented as software.
	You can have multiple network interfaces operating at once. Specific interfaces can be brought up (activated) or brought down (de-activated) at any time.
	Information about a particular network interface or all network interfaces can be reported by the ip and ifconfig utilities, which you may have to run as the superuser, or at least, give the full path, i.e. /sbin/ifconfig, on some distributions. ip is newer than ifconfig  and has far more capabilities, but its output is uglier to the human eye.
	Note: Some new Linux distributions do not install the older net-tools package to which ifconfig belongs, and  so you would have to install it if you want to use it.
ip
	ip is a very powerful program that can do many things. Older (and more specific) utilities such as ifconfig and route are often used to accomplish similar tasks.
		/sbin/ip addr show - To view the IP address
		/sbin/ip route show - To view the routing information
		ip route - Show current routing table
		ip route show
		ip route add - Add static route
		ip route del - Delete static route
		ip --brief addr show - To get id address
route
	to view or change the IP routing table to add, delete, or modify specific (static) routes to specific hosts or networks.
		route –n - Show current routing table
		route add -net address - Add static route
		route del -net address - Delete static route
traceroute
	to inspect the route which the data packet takes to reach the destination host, which makes it quite useful for troubleshooting network delays and errors.
	By using traceroute, you can isolate connectivity issues between hops, which helps resolve them faster.
		traceroute <address>
		sudo traceroute 8.8.8.8
additional networking tools
	ethtool: Queries network interfaces and can also set various parameters such as the speed
		sudo ethtool eth0
	netstat: Displays all active connections and routing tables. Useful for monitoring performance and troubleshooting
		netstat -r
	nmap: Scans open ports on a network. Important for security analysis
		sudo nmap -sP 10.0.2.15/24
	tcpdump: Dumps network traffic for analysis
	iptraf: Monitors network traffic in text mode
	mtr: Combines functionality of ping and traceroute and gives a continuously updated display
		sudo mtr --report-cycles 3 8.8.8.8
	dig: Tests DNS workings. A good replacement for host and nslookup
		dig google.com
name
	hostname - show or set the system's host name
	domainname/ypdomainname/nisdomainname - show or set the system's NIS/YP domain name
	dnsdomainname - show the system's DNS domain name
DNS
	/etc/hosts
	/etc/resolv.conf
		host linuxfoundation.org - To look up hostnames using DNS
		nslookup linuxfoundation.org - To look up name servers interactively
		dig google.com - To look up domain name information from nameserver
NAT
	Network Address Translation.
	NAT enables sharing one IP address among many locally connected computers, each of which has a unique address only seen on the local network.
DHCP
	Dynamic Host Configuration Protocol.
	It is used to assign IP addresses.
		sudo dhclient eth0
IPv4
	A 32-bit IPv4 address is divided into four 8-bit sections called octets.
		172.16.31.46
	Note: The value of an octet, or 8-bits, can range from 0 to 255.
	Network addresses are divided into five classes: A, B, C, D, E. Network addresses (NetID) and Host address (HostID). The NetID is used to identify the network, while the HostID is used to identify a host in the network. Class D is used for special multicast applications (information is broadcast to multiple computers simultaneously) and Class E is reserved for future use.
	  octet1 octet2 octet3 octet4
	A  NetID HostID HostID HostID
	B  NetID  NetID HostID HostID
	C  NetID  NetID  NetID HostID
	D     Multi-cast addresses
	E   Reserved for future use
	
	Class A.
	Class A addresses use the first octet of an IP address as their NetID and use the other three octets as the HostID.
	The first bit of the first octet is always set to zero. So you can use only 7-bits for unique network numbers. As a result, there are a maximum of 126 Class A networks available (the addresses 0000000 and 1111111 are reserved).
	Each Class A network can have up to 16.7 million unique hosts on its network. The range of host address is from 1.0.0.0 to 127.255.255.255.
	Class B.
	Class B addresses use the first two octets of the IP address as their NetID and the last two octets as the HostID.
	The first two bits of the first octet are always set to binary 10, so there are a maximum of 16,384 (14-bits) Class B networks. The first octet of a Class B address has values from 128 to 191.
	Each Class B network can support a maximum of 65,536 unique hosts on its network. The range of host address is from 128.0.0.0 to 191.255.255.255.
	Class C.
	Class C addresses use the first three octets of the IP address as their NetID and the last octet as their HostID.
	The first three bits of the first octet are set to binary 110, so almost 2.1 million (21-bits) Class C networks are available. The first octet of a Class C address has values from 192 to 223.
	Each Class C network can support up to 256 (8-bits) unique hosts. The range of host address is from 192.0.0.0 to 223.255.255.255.
non-graphical browsers
	Lynx: Configurable text-based web browser; the earliest such browser and still in use
	ELinks: Based on Lynx. It can display tables and frames
	w3m: Another text-based web browser with many features.
command line FTP clients
	ftp, sftp, ncftp, yafc (Yet Another FTP Client).
		ftp –p aristotle.learningmate.com
ssh
	Secure Shell is a cryptographic network protocol used for secure data communication.
	It is also used for remote services and other secure services between two devices on the network and is very useful for administering systems which are not easily available to physically work on, but to which you have remote access.
		ssh some_system - to login to a remote system
		ssh -l someone some_system - to run as another user
		ssh someone@some_system
		ssh some_system my_command - to run a command on a remote system via SSH
	Note: You can also configure ssh to securely allow your remote access without typing a password each time.
scp
	to copy files securely using Secure Copy (scp) between two networked hosts. scp uses the SSH protocol for transferring data.
		scp <localfile> <user@remotesystem>:/home/user/
	Note: You can also configure scp so that it does not prompt for a password for each transfer.
command shell choices
	The command interpreter is tasked with executing statements that follow it in the script.
	Commonly used interpreters include: /usr/bin/perl, /bin/bash, /bin/csh, /usr/bin/python and /bin/sh.
	Linux provides a wide choice of shells; exactly what is available on the system is listed in /etc/shells.
	Most Linux users use the default bash shell.
bash basic syntax and special characters
	# - to add a comment, except when used as \#, or as #! when starting a script
	\ - at the end of a line to indicate continuation on to the next line
	; - to interpret what follows as a new command to be executed next
		make; make install; make clean
	$ - to indicate an environment variable
	> - to redirect output
		free > /tmp/free.out
	>> - to append output to a file if it exists, and act just like > if the file does not already exist
	< - to redirect input
		wc < /etc/passwd
	| - to pipe the result into the next command
	&& - to abort subsequent commands when an earlier one fails
		make && make install && make clean
	|| - to proceed until something succeeds and then you stop executing any further steps
		cat file1 || cat file2 || cat file3
script parameters
	$0 - Script name
	$1 - First parameter
	$2, $3, etc. - Second, third parameter, etc.
	$* - All parameters
	$# - Number of arguments
command substitution
	It can be done in two ways:
	1. By enclosing the inner command in $( )
	2. By enclosing the inner command with backticks (`)
	Note: backticks form, is deprecated in new scripts and commands.
	The specified command will be executed in a newly launched shell environment, and the standard output of the shell will be inserted where the command substitution is done.
		ls /lib/modules/$(uname -r)/
if statement
	In compact form, the syntax of an if statement is:
	if TEST-COMMANDS; then CONSEQUENT-COMMANDS; fi
	A more general definition is:
	if condition
	then
	  statements
	else
	  statements
	fi
	In the following example, an if statement checks to see if a certain file exists, and if the file is found, it displays a message indicating success or failure:
	if [ -f "$1" ]
	then
	  echo file "$1 exists" 
	else
	  echo file "$1" does not exist
	fi
	In modern scripts, you may see doubled brackets as in[[ -f /etc/passwd ]]. It is never wrong to do so and it avoids some subtle problems, such as referring to an empty environment variable without surrounding it in double quotes;
	You can use the elif statement to perform more complicated tests, and take action appropriate actions.
	if [ sometest ] ; then
	  echo Passed test1 
	elif [ somothertest ] ; then
	  echo Passed test2 
	fi
	bash provides a set of file conditionals, that can be used with the if statement:
	-e file - if the file exists
	-d file -  if the file is a directory
	-f file - if the file is a regular file (i.e. not a symbolic link, device node, directory, etc.)
	-s file - if the file is of non-zero size
	-g file - if the file has sgid set
	-u file - if the file has suid set
	-r file - if the file is readable
	-w file - if the file is writable
	-x file - if the file is executable
	Note: You can view the full list of file conditions: man 1 test
	Numerical Tests:
	The syntax for comparing numbers is as follows - exp1 -op exp2
		[ $number1 -gt $number2 ] - The operator -gt returns TRUE if number1 is greater than number2
	Operators:
	-eq - Equal to
	-ne - Not equal to
	-gt - Greater than
	-lt - Less than
	-ge - Greater than or equal to
	-le - Less than or equal to
Arithmetic expressions
	Arithmetic expressions can be evaluated in the following three ways (spaces are important!):
	Using the expr utility. expr is a standard but somewhat deprecated program.
		expr 8 + 8
		echo $(expr 8 + 8)
	Using the $((...)) syntax. This is the built-in shell format.
		echo $((x+1))
	Using the built-in shell command let.
		let x=( 1 + 2 ); echo $x
	In modern shell scripts, the use of expr is better replaced with var=$((...)).
string manipulation
	A string variable contains a sequence of text characters.
	It can include letters, numbers, symbols and punctuation marks.
		abcde, 123, abcde 123, abcde-123, &acbde=%123
	String operators include those that do comparison, sorting, and finding the length.
	Basic string operators:
	[[ string1 > string2 ]] - to compare the sorting order of string1 and string2
	[[ string1 == string2 ]] - to compare the characters in string1 with the characters in string2
	myLen1=${#string1} - to saves the length of string1 in the variable myLen1
	${string:0:n} - to extract the first n characters of a string
	${string#*.} - to extract all characters in a string after a dot (.)
case statement
	case expression in
	  pattern1) execute commands;;
	  pattern2) execute commands;;
	  pattern3) execute commands;;
	  pattern4) execute commands;;
	  * )       execute some default commands or nothing ;;
	esac
loop statement
	1. The for loop operates on each element of a list of items.
	for variable-name in list
	do
	  execute one iteration for each item in the list until the list is finished
	done
	2. The while loop repeats a set of statements as long as the control command returns true.
	while condition is true
	do
	  Commands for execution
	done
	3. The until loop repeats a set of statements as long as the control command is false.
	until condition is false
	do
	  Commands for execution
	done
script debug mode
	You can run a bash script in debug mode either by doing bash –x ./script_file,  or bracketing parts of the script with set -x and set +x.
	In debug mode:
	1) It traces and prefixes each command with the + character.
	2) It displays each command before executing it.
	3) It can debug only selected parts of a script (set -x/set +x).
		set -x # turns on debugging
		set +x # turns off debugging
mktemp
	Creates temporary files or directories.
		TEMP=$(mktemp /tmp/tempfile.XXXXXXXX) # To create a temporary file
		TEMPDIR=$(mktemp -d /tmp/tempdir.XXXXXXXX) # To create a temporary directory
		Note: The XXXXXXXX is replaced by the mktemp with random characters to ensure the name of the temporary file cannot be easily predicted and is only known within your program.
CUPS
	Common UNIX Printing System.
	It acts as a print server for both local and network printers.
	After executing a print command, the scheduler validates the command and processes the print job, creating job files according to the settings specified in the configuration files. Simultaneously, the scheduler records activities in the log files. Job files are processed with the help of the filter, printer driver, and backend, and then sent to the printer.
	The CUPS web interface is available at: http://localhost:631
	CUPS carries out the printing process with the help of its various components:
	1) Configuration Files
	CUPS related configuration files are stored under the /etc/cups/;
		cupsd.conf - is where most system-wide settings are located; it does not contain any printer-specific details. Most of the settings available in this file relate to network security, i.e. which systems can access CUPS network capabilities, how printers are advertised on the local network, what management features are offered, and so on.
		printers.conf - is where you will find the printer-specific settings. For every printer connected to the system, a corresponding section describes the printer’s status and capabilities. This file is generated only after adding a printer to the system and should not be modified by hand.
	2) Scheduler
	manages print jobs, handles administrative commands, allows users to query the printer status, and manages the flow of data through all CUPS components;
	browser-based interface allows to view and manipulate the order and status of pending print jobs;
	3) Job Files
	CUPS stores print requests as files under the /var/spool/cups directory (these can actually be accessed before a document is sent to a printer). Data files are prefixed with the letter "d" while control files are prefixed with the letter "c".
	After a printer successfully handles a job, data files are automatically removed. These data files belong to what is commonly known as the print queue.
	4) Log Files
	Log files are placed in /var/log/cups and are used by the scheduler to record activities that have taken place. These files include access, error, and page records.
	5) Filter
	CUPS uses filters to convert job file formats to printable formats. Printer drivers contain descriptions for currently connected and configured printers, and are usually stored under /etc/cups/ppd/. The print data is then sent to the printer through a filter and via a backend that helps to locate devices connected to the system.
	6) Printer Drivers
	7) Backend
	Managing CUPS: all management features can be done with the systemctl utility.
		systemctl status cups
		sudo systemctl [enable|disable] cups
		sudo systemctl [start|stop|restart] cups
	Printing from the Command-Line Interface
	lp (System V) or lpr (BSD)
		lp <filename> # To print the file to default printer
		lp -d printer <filename> # To print to a specific printer (useful if multiple printers are available)
		program | lp
		echo string | lp # To print the output of a program
		lp -n number <filename> # To print multiple copies
		lpoptions -d printer # To set the default printer
		lpq -a # To show the queue status
		lpadmin # To configure printer queues
	The lpoptions utility can be used to set printer options and defaults. Each printer has a set of tags associated with it, such as the default number of copies and authentication requirements. You can execute the command lpoptions help to obtain a list of supported options. lpoptions can also be used to set system-wide values, such as the default printer.
		lpstat -p -d # To get a list of available printers, along with their status
		lpstat -a # To check the status of all connected printers, including job numbers
		cancel job-id
		lprm job-id # To cancel a print job
		lpmove job-id newprinter # To move a print job to new printer
PostScript
	PostScript is a standard page description language.
	It effectively manages scaling of fonts and vector graphics to provide quality printouts. It is purely a text format that contains the data fed to a PostScript interpreter. The format itself is a language that was developed by Adobe in the early 1980s to enable the transfer of data to printers.
	Features:
	1. It can be used on any printer that is PostScript-compatible; i.e. any modern printer
	2. Any program that understands the PostScript specification can print to it
	3. Information about page appearance, etc. is embedded in the page.
	Note: Postscript has been for the most part superseded by the PDF format (Portable Document Format) which produces far smaller files in a compressed format for which support has been integrated into many applications. However, one still has to deal with postscript documents, often as an intermediate format on the way to producing final documents.
enscript
	A tool that is used to convert a text file to PostScript and other formats. It also supports Rich Text Format (RTF) and HyperText Markup Language (HTML).
		enscript -2 -r -p psfile.ps textfile.txt # To convert a text file to two columns (-2) formatted PostScript
		enscript -p psfile.ps textfile.txt # To convert a text file to PostScript (saved to psfile.ps)
		enscript -n -p psfile.ps textfile.txt # To convert a text file to n columns where n=1-9 (saved in psfile.ps)
		enscript textfile.txt # To print a text file directly to the default printer
converting between PostScript and PDF
	ps2pdf and pdf2ps are part of the ghostscript package installed on or available on all Linux distributions. As an alternative, there are pstopdf and pdftops which are usually part of the poppler package, which may need to be added through your package manager. Unless you are doing a lot of conversions or need some of the fancier options (which you can read about in the man pages for these utilities), it really does not matter which ones you use.
	Another possibility is to use the very powerful convert program, which is part of the ImageMagick package.
		pdf2ps file.pdf # To convert file.pdf to file.ps
		ps2pdf file.ps # To converts file.ps to file.pdf
		pstopdf input.ps output.pdf # To converts input.ps to output.pdf
		pdftops input.pdf output.ps # To converts input.pdf to output.ps
		convert input.ps output.pdf # To converts input.ps to output.pdf
		convert input.pdf output.ps # To converts input.pdf to output.ps
Linux PDF readers
	Evince is available on virtually all distributions and the most widely used program.
	Okular is based on the older kpdf and available on any distribution that provides the KDE environment.
	GhostView is one of the first open source PDF readers and is universally available.
	Xpdf is one of the oldest open source PDF readers and still has a good user base.
pdftk
	https://www.pdflabs.com/
	PDF Toolkit for:
	1. Merging/Splitting/Rotating PDF documents
	2. Repairing corrupted PDF pages
	3. Pulling single pages from a file
	4. Encrypting and decrypting PDF files
	5. Adding, updating, and exporting a PDF’s metadata
	6. Exporting bookmarks to a text file
	7. Filling out PDF forms.
		sudo apt-get install pdftk # To install pdftk on Ubuntu
		snap install pdftk # Ubuntu 18.04 (and the binary will reside at: /snap/bin/pdftk)
		sudo yum install pdftk # CentOS 6
		sudo zypper install pdftk # openSUSE
		
		pdftk 1.pdf 2.pdf cat output 12.pdf # To merge the two documents 1.pdf and 2.pdf. The output will be saved to 12.pdf.
		pdftk A=1.pdf cat A1-2 output new.pdf # To write only pages 1 and 2 of 1.pdf. The output will be saved to new.pdf.
		pdftk A=1.pdf cat A1-endright output new.pdf # To rotate all pages of 1.pdf 90 degrees clockwise and save result in new.pdf.
		pdftk public.pdf output private.pdf user_pw PROMPT # To encrypt
ghostscript
	Ghostscript is widely available as an interpreter for the Postscript and PDF languages.
	The executable program associated with it is abbreviated to gs.
	This utility can do most of the operations pdftk can, as well as many others. Use is somewhat complicated by the rather long nature of the options.
		gs -dBATCH -dNOPAUSE -q -sDEVICE=pdfwrite  -sOutputFile=all.pdf file1.pdf file2.pdf file3.pdf # To combine three PDF files into one
		gs -sDEVICE=pdfwrite -dNOPAUSE -dBATCH -dDOPDFMARKS=false -dFirstPage=10 -dLastPage=20 -sOutputFile=split.pdf file.pdf # To split pages 10 to 20 out of a PDF file
pdfinfo
	It can extract information about PDF files, especially when the files are very large or when a graphical interface is not available.
		pdfinfo /usr/share/doc/readme.pdf
flpsed
	It can add data to a PostScript document. This tool is specifically useful for filling in forms or adding short comments into the document.
pdfmod
	It is a simple application that provides a graphical interface for modifying PDF documents. Using this tool, you can reorder, rotate, and remove pages; export images from a document; edit the title, subject, and author; add keywords; and combine documents using drag-and-drop action.
user account
	Command line programs such as useradd and userdel as well as GUI tools are used for creating and removing accounts.
	For each user, the following fields are maintained in the /etc/passwd file:
	1) Username.
	User login name. Should be between 1 and 32 characters long.
	2) Password.
	User password (or the character x if the password is stored in the /etc/shadow file) in encrypted format. Is never shown in Linux when it is being typed; this stops prying eyes.
	3) User ID (UID).
	Every user must have a user id (UID).
	UID 0 is reserved for root user.
	UID's ranging from 1-99 are reserved for other predefined accounts.
	UID's ranging from 100-999 are reserved for system accounts and groups.
	Normal users have UID's of 1000 or greater.
	4) Group ID (GID).
	The primary Group ID (GID).
	Group Identification Number stored in the /etc/group file.
	5) User Info.
	This field is optional and allows insertion of extra information about the user such as their name.
	6) Home Directory.
	The absolute path location of user's home directory.
	7) Shell.
	The absolute location of a user's default shell.
	Note: On modern systems, passwords are actually stored in an encrypted format in a secondary file named /etc/shadow. Only those with root access can modify/read this file.
types of accounts
	By default, Linux distinguishes between several account types in order to isolate processes and workloads:
	1) root
	2) System
	3) Normal
	4) Network
operations requiring root privileges
	1) Creating, removing and managing user accounts
	2) Managing software packages
	3) Removing or modifying system files
	4) Restarting system services
	Note: Regular account users of Linux distributions might be allowed to install software packages, update some settings, use some peripheral devices, and apply various kinds of changes to the system. However, root privilege is required for performing administration tasks such as restarting services, manually installing packages and managing parts of the filesystem that are outside the normal user’s directories.
operations not requiring root privileges
	1) Running a network client
	2) Using devices such as printers
	3) Operations on files that the user has proper permissions to access
	4) Running SUID-root applications (executing programs such as passwd)
	A regular account user can perform some operations requiring special permissions; however, the system configuration must allow such abilities to be exercised.
	SUID (Set owner User ID upon execution) is a special kind of file permission given to a file. SUID provides temporary permissions to a user to run a program with the permissions of the file owner (which may be root) instead of the permissions held by the user.
additional security mechanisms
	Control Groups (cgroups)
	Allows system administrators to group processes and associate finite resources to each cgroup.
	
	Containers
	Makes it possible to run multiple isolated Linux systems (containers) on a single system by relying on cgroups.

	Virtualization
	Hardware is emulated in such a way that not only processes can be isolated, but entire systems are run simultaneously as isolated and insulated guests (virtual machines) on one physical host.
password algorithm
	Most Linux distributions rely on a modern password encryption algorithm called SHA-512 (Secure Hashing Algorithm 512 bits), developed by the U.S. National Security Agency (NSA) to encrypt passwords.
	The SHA-512 algorithm is widely used for security applications and protocols. These security applications and protocols include TLS, SSL, PHP, SSH, S/MIME and IPSec. SHA-512 is one of the most tested hashing algorithms.
		echo -n test | sha512sum
password practices
	1. aging.
	A method to ensure that users get prompts that remind them to create a new password after a specific period. This can ensure that passwords, if cracked, will only be usable for a limited amount of time.
		chage --list newuser # configures the password expiry information for a user
		sudo chage -E 2020-31-12 newuser # to modify the expiration date
	2. Pluggable Authentication Modules (PAM). PAM can be configured to automatically verify that a password created or modified using the passwd utility is sufficiently strong. PAM configuration is implemented using a library called pam_cracklib.so, which can also be replaced by pam_passwdqc.so for more options.
	3. One can also install password cracking programs, such as John The Ripper, to secure the password file and detect weak password entries. It is recommended that written authorization be obtained before installing such tools on any system that you do not own.
boot loader password
	GRUB 2 Password Protection - https://help.ubuntu.com/community/Grub2/Passwords
hardware vulnerability
	When hardware is physically accessible, security can be compromised by:
	1) Key logging.
	Recording the real time activity of a computer user including the keys they press. The captured data can either be stored locally or transmitted to remote machines.
	2) Network sniffing.
	Capturing and viewing the network packet level data on your network.
	3) Booting with a live or rescue disk.
	4) Remounting and modifying disk content.
	The guidelines of security are:
	1) Lock down workstations and servers.
	2) Protect your network links such that it cannot be accessed by people you do not trust.
	3) Protect your keyboards where passwords are entered to ensure the keyboards cannot be tampered with.
	4) Ensure a password protects the BIOS in such a way that the system cannot be booted with a live or rescue DVD or USB key.
